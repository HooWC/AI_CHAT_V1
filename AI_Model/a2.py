# a2_fixed.py
from transformers import AutoTokenizer, AutoModel
import torch

class ChineseChatbot:
    def __init__(self, model_name="THUDM/chatglm3-6b"):
        """
        ChatGLM3-6Bæ˜¯æ¸…åå¤§å­¦çš„å¼€æºä¸­æ–‡å¯¹è¯æ¨¡å‹
        ä¸“é—¨ä¸ºä¸­æ–‡å¯¹è¯ä¼˜åŒ–ï¼Œæ•ˆæœéå¸¸å¥½
        """
        print(f"æ­£åœ¨åŠ è½½ {model_name}...")
        print("âš ï¸ æ³¨æ„ï¼šé¦–æ¬¡ä¸‹è½½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆçº¦12GBï¼‰")
        
        # ä¿®å¤ï¼šä½¿ç”¨ dtype æ›¿ä»£ torch_dtype
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_name, 
            trust_remote_code=True
        )
        
        # æ ¹æ®ç¡¬ä»¶è‡ªåŠ¨é€‰æ‹©æ•°æ®ç±»å‹
        if torch.cuda.is_available():
            print("âœ… æ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
            dtype = torch.float16  # åŠç²¾åº¦èŠ‚çœæ˜¾å­˜
        else:
            print("âš ï¸ ä½¿ç”¨CPUæ¨¡å¼ï¼ˆè¾ƒæ…¢ï¼‰")
            dtype = torch.float32
        
        self.model = AutoModel.from_pretrained(
            model_name,
            trust_remote_code=True,
            device_map="auto",  # è‡ªåŠ¨é€‰æ‹©GPU/CPU
            dtype=dtype,  # ä¿®å¤ï¼šä½¿ç”¨ dtype
            low_cpu_mem_usage=True  # å‡å°‘CPUå†…å­˜ä½¿ç”¨
        ).eval()
        
        self.history = []
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")
        print("ğŸ’¡ æç¤ºï¼šè¿™æ˜¯ä¸“é—¨çš„ä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼Œæ”¯æŒå¤šè½®å¯¹è¯")
    
    def chat(self, user_input, max_length=4096):
        # ä½¿ç”¨ChatGLMçš„å†…ç½®å¯¹è¯æ¥å£
        response, self.history = self.model.chat(
            self.tokenizer,
            user_input,
            history=self.history,
            max_length=max_length,
            temperature=0.7
        )
        
        # ä¿æŒå†å²é•¿åº¦
        if len(self.history) > 20:
            self.history = self.history[-20:]
        
        return response
    
    def clear_history(self):
        self.history = []
        return "å¯¹è¯å†å²å·²æ¸…ç©º"

def main():
    print("=" * 60)
    print("ğŸ¤– ä¸­æ–‡å¯¹è¯æœºå™¨äºº - ChatGLM3-6B")
    print("=" * 60)
    print("ç‰¹ç‚¹ï¼š")
    print("â€¢ æ¸…åå¤§å­¦å¼€å‘ï¼Œä¸“é—¨ä¸ºä¸­æ–‡ä¼˜åŒ–")
    print("â€¢ æ”¯æŒä¸Šä¸‹æ–‡ç†è§£ï¼ˆå¤šè½®å¯¹è¯ï¼‰")
    print("â€¢ ä»£ç ã€æ•°å­¦ã€æ¨ç†èƒ½åŠ›å¼º")
    print("â€¢ å®Œå…¨å…è´¹å¼€æº")
    print("-" * 60)
    
    try:
        bot = ChineseChatbot()
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        print("\nğŸ’¡ å»ºè®®ï¼š")
        print("1. å¦‚æœä¸æƒ³ä¸‹è½½12GBå¤§æ¨¡å‹ï¼Œè¯·æŒ‰ Ctrl+C ä¸­æ–­")
        print("2. ä½¿ç”¨ä¸‹é¢çš„è½»é‡çº§æ›¿ä»£æ–¹æ¡ˆ")
        return
    
    print("\nğŸ’¬ å¼€å§‹å¯¹è¯ï¼ˆè¾“å…¥ 'é€€å‡º' ç»“æŸï¼Œ'clear' æ¸…ç©ºå†å²ï¼‰")
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ ä½ : ").strip()
        except KeyboardInterrupt:
            print("\nğŸ¤– AI: å†è§ï¼")
            break
        
        if user_input.lower() in ['é€€å‡º', 'exit', 'quit']:
            print("ğŸ¤– AI: å†è§ï¼æœŸå¾…ä¸‹æ¬¡èŠå¤©ï¼")
            break
        elif user_input.lower() in ['clear', 'æ¸…ç©º', 'æ¸…é™¤']:
            result = bot.clear_history()
            print(f"ğŸ¤– AI: {result}")
            continue
        
        try:
            response = bot.chat(user_input)
            print(f"ğŸ¤– AI: {response}")
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    main()