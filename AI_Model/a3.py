from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

class ChineseChatbot:
    def __init__(self):
        # ä½¿ç”¨é˜¿é‡Œå·´å·´çš„ Qwen2.5 0.5B æŒ‡ä»¤å¾®è°ƒç‰ˆ
        self.model_name = "Qwen/Qwen2.5-0.5B-Instruct"
        print(f"æ­£åœ¨åŠ è½½ä¸­æ–‡æ¨¡å‹ {self.model_name}...")
        print("æ¨¡å‹å¤§å°ï¼šçº¦ 950MBï¼Œåˆæ¬¡åŠ è½½å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´...")
        
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            torch_dtype="auto",
            device_map="auto" # è‡ªåŠ¨æ£€æµ‹ GPU æˆ– CPU
        )
        
        # å­˜å‚¨å¯¹è¯å†å²
        self.messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ä¸­æ–‡ AI åŠ©æ‰‹ã€‚"}
        ]
        
        print("âœ… ä¸­æ–‡æ¨¡å‹åŠ è½½å®Œæˆï¼")

    def chat(self, user_input):
        # 1. å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°å†å²è®°å½•
        self.messages.append({"role": "user", "content": user_input})
        
        # 2. ä½¿ç”¨æ¨¡æ¿å¤„ç†å¯¹è¯æ ¼å¼
        text = self.tokenizer.apply_chat_template(
            self.messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        # 3. ç¼–ç è¾“å…¥
        model_inputs = self.tokenizer([text], return_tensors="pt").to(self.model.device)
        
        # 4. ç”Ÿæˆå›å¤
        # æ³¨æ„ï¼šè¿™é‡Œè§£å†³äº†ä½ ä¹‹å‰é‡åˆ°çš„ attention_mask å’Œ pad_token é—®é¢˜
        generated_ids = self.model.generate(
            **model_inputs,
            max_new_tokens=512,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            repetition_penalty=1.1
        )
        
        # 5. æå–æ–°ç”Ÿæˆçš„ token
        generated_ids = [
            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
        ]
        
        # 6. è§£ç å¹¶ä¿å­˜åˆ°å†å²è®°å½•
        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
        self.messages.append({"role": "assistant", "content": response})
        
        return response

    def clear_history(self):
        self.messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ä¸­æ–‡ AI åŠ©æ‰‹ã€‚"}]
        return "å¯¹è¯å†å²å·²æ¸…ç©º"

def main():
    print("=" * 60)
    print("ğŸ¤– å…è´¹ä¸­æ–‡å¯¹è¯æœºå™¨äºº - Qwen2.5-0.5B")
    print("=" * 60)
    print("âœ“ å®Œå…¨å…è´¹ | âœ“ æ”¯æŒä¸­æ–‡ | âœ“ æœ¬åœ°è¿è¡Œ")
    print("-" * 60)
    
    bot = ChineseChatbot()
    
    print("\nğŸ’¬ å¼€å§‹å¯¹è¯ï¼ˆè¾“å…¥ 'é€€å‡º' ç»“æŸï¼Œ'clear' æ¸…ç©ºå†å²ï¼‰")
    
    while True:
        user_input = input("\nğŸ‘¤ ä½ : ").strip()
        
        if user_input.lower() in ['é€€å‡º', 'quit', 'exit']:
            print("ğŸ¤– AI: å†è§ï¼ç¥ä½ å¼€å¿ƒæ¯ä¸€å¤©ï¼ ğŸ‘‹")
            break
        elif user_input.lower() == 'clear':
            result = bot.clear_history()
            print(f"ğŸ¤– AI: {result}")
            continue
        
        if not user_input:
            continue
        
        try:
            response = bot.chat(user_input)
            print(f"ğŸ¤– AI: {response}")
        except Exception as e:
            print(f"âŒ å‡ºé”™å•¦: {e}")

if __name__ == "__main__":
    main()